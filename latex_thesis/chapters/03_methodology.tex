\chapter{Methodology: The GeoSpatial Inference Pipeline (GSIP)}
\label{ch:methodology}

\section{System Design Philosophy}

The GeoSpatial Inference Pipeline (GSIP) is designed as a high-throughput, fault-tolerant system for operating on raster data that exceeds system memory. It adheres to the \textbf{Principle of Separation of Concerns}: the \textit{Physical Tiling} (how data is moved from disk to RAM) is decoupled from the \textit{Logical Inference} (what the neural network actually does).

\subsection{The Adapter Pattern}
To ensure the system remains model-agnostic, GSIP employs the \textbf{Adapter Design Pattern}. The core engine does not import `torchvision.models.resnet` or `transformers.Prithvi`. Instead, it interacts with a `BaseAdapter` abstract interface.

\begin{lstlisting}[language=Python, caption=The BaseAdapter Interface]
class BaseAdapter(ABC):
    @abstractmethod
    def preprocess(self, chunk: np.ndarray) -> torch.Tensor:
        """Normalizes raw pixels to model distribution (e.g. z-score)."""
        pass

    @abstractmethod
    def postprocess(self, logits: torch.Tensor) -> np.ndarray:
        """Converts raw logits to probability maps or class indices."""
        pass
    
    @property
    def input_shape(self) -> Tuple[int, int]:
        """Returns required (Height, Width) e.g., (224, 224)."""
        pass
\end{lstlisting}

This polymorphism allows the pipeline to act as a universal "driver." Whether the underlying model is a binary flood detector (1 output channel) or a multi-spectral land cover classifier (19 output channels), the pipeline logic remains identical.

\subsection{The Reporter Pattern}
While the Adapter Pattern abstracts the \textit{input} and \textit{model execution}, the \textbf{Reporter Pattern} abstracts the \textit{output generation}. In scientific workflows, the desired artifact varies widely: one user might need a pixel-perfect segmentation map (GeoTIFF), another a quick visual preview (PNG), and a third a statistical summary of class distributions (JSON).

To avoid polluting the core inference loop with format-specific I/O logic, GSIP delegates result handling to `BaseReporter` implementations.

\begin{lstlisting}[language=Python, caption=The BaseReporter Interface]
class BaseReporter(ABC):
    @abstractmethod
    def on_chunk(self, data: Dict[str, Any]):
        """Receives reconstructed probabilities for a specific spatial region."""
        pass
\end{lstlisting}

This architecture allows for "plug-and-play" output modules. For example, the `GlobalProbabilityReporter` implements an online algorithm to compute the global average pooling of the entire gigapixel image without ever holding the full uncompressed array in memory, saving terabytes of RAM for large-scale runs.

\section{The Memory Model: Zone of Responsibility}

A critical innovation of GSIP is the \textbf{Zone of Responsibility (ZoR)} algorithm. In standard deep learning scripts, the "batch size" and "tile size" are often hardcoded hyperparameters. This works for homogenous cluster environments but fails in heterogeneous deployment (e.g., moving from a DGX station to a laptop).

GSIP inverts this dependency. It views the \textit{Available RAM} as the independent variable and the \textit{Tile Size} as the dependent variable.

\subsection{The Cost Function}
We define the memory cost function for processing a single spatial chunk of dimensions $L \times L$ as:

\[
M_{total}(L) = M_{input}(L) + M_{gpu}(L) + M_{logits}(L) + M_{recon}(L) + C_{overhead}
\]

Where:
\begin{itemize}
    \item $M_{input} \approx L^2 \cdot B_{in} \cdot 4 \text{ bytes}$ (Float32 Input Tensor)
    \item $M_{logits} \approx L^2 \cdot C_{out} \cdot 4 \text{ bytes}$ (Float32 Output Logits)
    \item $M_{recon} \approx L^2 \cdot C_{out} \cdot 4 \text{ bytes}$ (Accumulation Buffer)
\end{itemize}

For a segmentation task with $C_{out}=19$ classes (BigEarthNet), the output tensors dominate.
The algorithm solves for the maximum $L$ such that $M_{total}(L) < \alpha \cdot \text{RAM}_{available}$, where $\alpha \approx 0.8$ is a safety factor.

\subsection{Dynamic Resolution}
At runtime, the \texttt{calculate\_optimal\_zor()} function probes the OS (via \texttt{psutil}) to determine free memory. It iteratively tests increasing values of $L$ (e.g., 1024, 2048, 4096) until the cost function approaches the safety limit. This ensures that the system maximally utilizes available resources without triggering the OS Out-Of-Memory (OOM) killer.

\section{Producer-Consumer Architecture}

Deep Learning inference on satellite imagery is a \textbf{Bound-Varying Problem}:
\begin{enumerate}
    \item \textbf{I/O Bound:} Reading compressed GeoTIFFs from disk.
    \item \textbf{Compute Bound:} Running the ResNet/ViT forward pass on GPU.
    \item \textbf{Memory Bound:} Merging the massive output probability maps.
\end{enumerate}

A sequential loop (\texttt{Read -> Infer -> Write}) would leave the GPU idle during Read/Write phases. GSIP utilizes a \textbf{Producer-Consumer} parallel architecture implemented via `torch.multiprocessing`.

\subsection{The Pipeline Flow}
\begin{enumerate}
    \item \textbf{Main Process (The Producer):}
    \begin{itemize}
        \item \textbf{Action:} Slices the large input image into the calculated "Chunks" (ZoR).
        \item \textbf{Action:} Performs "Lazy Reprojection" of Sentinel-1 data (using `rasterio.vrt`).
        \item \textbf{Action:} Pushes normalized tensors into the `Inference Queue`.
        \item \textit{Optimization:} Uses a background `Prefetcher` thread to ensure the Queue is never empty.
    \end{itemize}

    \item \textbf{Inference Engine (GPU Worker):}
    \begin{itemize}
        \item \textbf{Action:} Pulls batches from the queue.
        \item \textbf{Action:} Moves data to CUDA device (asynchronously).
        \item \textbf{Action:} Executes \texttt{model(x)} in \texttt{torch.no\_grad()} mode.
        \item \textbf{Action:} Pushes raw logits (on CPU) to the `Writer Queue`.
    \end{itemize}

    \item \textbf{Writer Process (The Consumer):}
    \begin{itemize}
        \item \textbf{Action:} Pulls logits.
        \item \textbf{Action:} Executes the \textbf{Sinusoidal Reconstruction} (see Chapter 4).
        \item \textbf{Action:} Computes Uncertainty metrics (Entropy).
        \item \textbf{Action:} Writes final GeoTIFFs to storage.
    \end{itemize}
\end{enumerate}

This architecture creates a "Pipelined" effect where the GPU is consistently saturated, masking the latency of disk I/O and CPU post-processing.

\section{Multi-Modal Fusion Strategy}

The pipeline natively handles sensor fusion. The configuration allows specifying multiple data sources.
\begin{itemize}
    \item \textbf{Logical Alignment:} The system treats the Sentinel-2 grid as the "Anchor."
    \item \textbf{Virtual Warping:} Sentinel-1 data is not physically reprojected on disk (which would double storage requirements). Instead, GSIP constructs a `WarperVRT` in memory. When a chunk is requested, GDAL computes the spline interpolation on-the-fly to align the SAR pixels with the Optical pixels. This "Virtual Data Cube" approach is essential for handling petabyte-scale archives where data duplication is prohibited.
\end{itemize}
